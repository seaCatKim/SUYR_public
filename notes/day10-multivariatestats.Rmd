---
title: "Day 10 - multivariate notes"
author: "Catherine Kim"
date: "22/10/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Day 10 Multivariate Statistics notes

So far have been low dimensional models. These don't work well for prediction.

Prediction is the domain of machine learning. Problem is we know they work but don't know how they work. Ecology is interested in the process of how it works. Understanding the systems is just as important as prediction.

## Classification & Regression Trees

- Reasonably good for prediction and can get an idea of the process. 
- Fewer assumptions
- Very good at handling multivariate data.

Regression provides a simple decision tree for prediction. 

> If temp is > this I expect that...

How do you split/**partition** data into 2 most different groups. Dichotymously split it.  Optimizes variance within and between 2 groups. Do it based on a **loss function**.

Different data types (counts, continuous, presenc/absence, categorical high/low/med etc. akin to distributions but different) have a different loss function.

Partitions for each predictor then compares which predictor is best. Starts with best predictor then incorporates other predictors as they become influential.

Overfit tree - want general patterns. Describing patterns of the system instead of a single observation.

Everything is contingent on first descision - picking the first predictor. Could have 2 predictors are very similar.

Fit a tree to half the data randomly sampled take the unlearned pattern (residuals) and fit another tree (tree on the residuals). Can run out of the pattern quickly - slow down the **learning rate**. Only taking a fraction of the pattern.

Fit an ensemble of trees in sequence.

> A large collection of really crap trees is always better than one really detailed tree.

Want to prune the tree.

> Extreme boosted tree - predicts Triple J top 100 20 spots with accuracy from Twitter data! Election predictions more about weights to address biases around who will answer a poll etc.

Need a way of stopping the partitioning to prevent over-learning. Prevent learning a unique feature of an observation versus a general system-level pattern.

Ways to prevent over-learning - cut-off:

1. **Test and training set**: Similar with GAMs wiggliness balance between explaining the data and some way of predicting other data never seen. Can do with trees - separate bin of data to train on and another to test. In ecology generally don't have that luxury to sacrifice data. 
2. **Out of Bag**: For smaller trees only sampling half the data. Every single tree we test have an opportunity to test prediction with the other half.
3. **Cross validation**: Fit a particular tree multiple times at a 'level' (instead of one at out of bag) and averaging and can assess how it is predicting between those trees. And then make the next tree based on the average residuals. Generally the best.

Want to aim for at least 1000 trees before cutting it off. Ideal 10k trees and slow learning rate. 40 or so trees not enough resolution for predictions.

Importance metric - how many splits are due to which predictor. A 5/6 vs B 1/6.

- If provide predictor that are meaningless will still get trees. With equal importance - A, B, C 1/3 each of splits.
- Can develop a quasi significance cut-off. Predictors less than meaningless variables would not be important. Explain less than would expect it. 





```{r cars}
summary(cars)
```

## Including Plots

You can also embed plots, for example:

```{r pressure, echo=FALSE}
plot(pressure)
```

Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.
