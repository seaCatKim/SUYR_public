---
title: "Bayesian GLM Part2"
author: "Murray Logan"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  html_document:
    code_folding: show
    collapse: no
    df_print: paged
    fig_caption: yes
    fig_height: 4
    fig_width: 4
    highlight: textmate
    theme: spacelab
    toc: yes
    toc_float: yes
    css: ../resources/style.css
  pdf_document:
    df_print: default
    fig_caption: yes
    fig_height: 4
    fig_width: 4
    highlight: tango
    latex_engine: xelatex
    number_sections: yes
    toc_depth: 2
  word_document:
    fig_caption: yes
    fig_height: 4
    fig_width: 4
    highlight: tango
    toc: yes
    toc_depth: 2
output_dir: "docs"
documentclass: article
fontsize: 12pt
mainfont: Arial
mathfont: LiberationMono
monofont: DejaVu Sans Mono
classoption: a4paper
bibliography: ../resources/references.bib
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message=FALSE, warning=FALSE)
```

# Preparations

Load the necessary libraries

```{r libraries, results='markdown', eval=TRUE}
library(rstanarm)   #for fitting models in STAN
library(brms)       #for fitting models in STAN
library(coda)       #for diagnostics
library(bayesplot)  #for diagnostics
library(ggmcmc)     #for MCMC diagnostics
library(DHARMa)     #for residual diagnostics
library(rstan)      #for interfacing with STAN
library(emmeans)    #for marginal means etc
library(broom)      #for tidying outputs
library(tidybayes)  #for more tidying outputs
library(ggeffects)  #for partial plots
library(tidyverse)  #for data wrangling etc
library(broom.mixed)#for summarising models
library(ggeffects)  #for partial effects plots
theme_set(theme_grey()) #put the default ggplot theme back
```

# Scenario

@Polis-1998-490 were intested in modelling the presence/absence of lizards (<i>Uta sp.</i>) against the perimeter to area ratio of 19 islands in the Gulf of California.

![Uta lizard](../resources/uta.jpg){width="200" height="137"}

Format of polis.csv data file

ISLAND       RATIO   PA
------------ ------- ----
Bota         15.41   1
Cabeza       5.63    1
Cerraja      25.92   1
Coronadito   15.17   0
..           ..      ..

------------ -----------------------------------------------------------------------------------------
**ISLAND**   Categorical listing of the name of the 19 islands used - variable not used in analysis.
**RATIO**    Ratio of perimeter to area of the island.
**PA**       Presence (1) or absence (0) of *Uta* lizards on island.
------------ -----------------------------------------------------------------------------------------


The aim of the analysis is to investigate the relationship between island parimeter to area ratio and the presence/absence of Uta lizards.

# Read in the data

```{r readData, results='markdown', eval=TRUE}
polis = read_csv('../data/polis.csv', trim_ws=TRUE)
glimpse(polis)
head(polis)
str(polis)
```

# Exploratory data analysis


Model formula:
$$
\begin{align}
y_i &\sim{} \mathcal{Bin}(n, p_i)\\
ln\left(\frac{p_i}{1-p_i}\right) &= \beta_0 + \beta_1 x_i\\
\beta_0 &\sim{} \mathcal{N}(0,10)\\
\beta_1 &\sim{} \mathcal{N}(0,1)\\
\end{align}
$$

p - calculated from eveything else. Don't need to estimate.

Need to estimate $\beta$s. 

Always normal priors on population effects. Everything on logit link scale. A small scale, so SD of 1 is still v diffuse.

```{r priors}
logit(0.5)

priors <- prior(normal(0, 10), class = 'Intercept') +
  prior(normal(0, 1), class = 'b')
```

# Fit the model {.tabset .tabset-faded}

Will skip default priors.

`trials(1)` is the 1 in $y \sim Bin(p, 1)$. Can only be 1 trial at a time.

When not using Gaussian and model is more complicated want a larger warmup.

`bf()` specific to writing formula in brms formula. Allows flexibility in types of models can fit particularly the non-linear models.

```{r fit prior model}
polis.brm1 <- brm(bf(PA|trials(1) ~ RATIO, family = binomial()), # include family in bf
                  data = polis,
                  prior = priors,
                  sample_prior = 'only', # assess just priors first
                  iter = 5000,
                  warmup = 2500,
                  chains = 3,
                  thin = 5
                  )
```

```{r check prior only}
polis.brm1 %>% ggemmeans(~ RATIO) %>% plot(add.data = TRUE)
```

```{r fit with data and priors}
polis.brm3 <- update(polis.brm1, sample_prior = 'yes')
```
Looks good.

```{r partial plot}
ggemmeans(polis.brm3, ~ RATIO) %>% plot(add.data = TRUE)
```

# MCMC sampling diagnostics {.tabset .tabset-faded}

Have intercept, slope, and priors for both.

All on link-scale which is why the prior is on the link scale.

```{r get model variables}
polis.brm3 %>% get_variables()
```

Prior does not appear to be influencing for the slope.

```{r check priors}
polis.brm3 %>% hypothesis('RATIO = 0') %>% plot()
```

# Model validation {.tabset .tabset-faded}

## Trace plots

Looks okay. Ideally a bit more compact could run a little longer.

```{r trace plots}
polis.brm3$fit %>% stan_trace()
```

## Autocorrelation

```{r autocorr}
polis.brm3$fit %>% stan_ac()
```


## Rhat

Want under 1.05. Really don't want parameters of interest to be 1.05 - can see here, but in summary.

```{r rhat}
polis.brm3$fit %>% stan_rhat()
```

## Efficiency

Sampling effectively, all very high.

```{r ESS}
polis.brm3$fit %>% stan_ess()
```

Sampler has done a good job. Expect that posterior is well mixed, stable, and has converged.

## Spaghetti

Not very useful for logit.

```{r spaghetti}
polis.brm3 %>% pp_check(type = 'dens_overlay', nsamples = 100)
```

## DHARMa

Looks good despite no quantiles.

```{r DHARMa}
polis %>% head()

preds <- polis.brm3 %>% posterior_predict(nsmaples = 250, summary = FALSE)
polis.resids <- createDHARMa(simulatedResponse = t(preds), # transpose matrix
                            observedResponse = polis$PA, # only thing that will change
                            fittedPredictedResponse = apply(preds, 2, median), # calc median for each column
                            integerResponse = FALSE)

polis.resids %>% plot()
```

# Partial effects plots {.tabset .tabset-faded}

Expectation is negative relationship. Inflection point around 15.

```{r partial plots}
# need to specify effect
polis.brm3 %>% ggemmeans(~ RATIO) %>% plot(add.data = TRUE) 

# better with lots of predictors will do all
polis.brm3 %>% conditional_effects() %>% 
  plot(points = TRUE)
```


# Model investigation {.tabset .tabset-faded}

Estimate of the intercept on logit scale. 

Island with RATIO of 0 - what is the probability lizards are present. ~99%
Could be as low as 80% or as high as 99.99%.

~95x more likely being presence than not being present.

Per unit of RATIO, gone down by ~25%. Only 75% of what it was.

Odds ratio fairly sensitive. What to look at whole distribution (credibility interval) vs just mean/median.

```{r summary}
polis.brm3 %>% summary()
plogis(4.55)
plogis(1.39)
plogis(9.34)

exp(4.55)  # 95
0.9895433/(1-0.9895433)

exp(-0.28) # .75 x per unit increase
94.63247 * 0.7557837
```

Own summary:

Interested in first two parameters. Could rename them or based on patterns espeically useful with lots of parameters.

^ - starts with: b_
* - anything

```{r own summary}
polis.brm3 %>% get_variables()

polis.draw <- polis.brm3 %>% gather_draws(b_Intercept, b_RATIO) # same as below
polis.draw <- polis.brm3 %>% gather_draws(`^b_.*`, regex = TRUE)
polis.draw

polis.draw %>% median_hdci()
```

# Further analyses {.tabset .tabset-faded}

What if wanted different scale from log odds for summary? Wanted odds ratio etc.

Median is different from mean above. Odds ration for the slope did not change massively.

```{r back transform}
polis.draw %>% 
  mutate(Odds = exp(.value)) %>% 
  median_hdci(Odds)
```

What is the probability that the likelihood of the lizards present does decline wtih increasing island ratio? What is the probability there is an effect.

.values on logit scale - always compare to 0. Could use either logit or odds scale, should be the same.

Very strong evidence of a negative relationship.

```{r back transform}
polis.draw %>% 
  mutate(Odds = exp(.value)) %>% 
  filter(.variable == 'b_RATIO') %>% 
  summarize(P = sum(.value < 0)/n(), # after negative slope
            P1 = sum(Odds < 1)/n())
```

Odds ratio - what's the probability the odds will decline by 50% (halving).

Very unlikely, change is not as dramatic as halving per unit increase.

Can test certain hypothesises. 

```{r odds}
polis.draw %>% 
  mutate(Odds = exp(.value)) %>% 
  filter(.variable == 'b_RATIO') %>% 
  summarize(P = sum(Odds < 0.5)/n())
```

## R2 value

Model explains ~53% of variability.

```{r r2}
polis.brm3 %>% bayes_R2(summary = FALSE) %>% 
  median_hdci()
```

## Calculate LD50

Need 2 things to calculate - intercept and slope.

-intercept / slope, on the link scale

Median LD50 is 16.4 with credible interval 10-23. Could test hypotheses - probability LD50 is less than 20.

```{r LD50}
polis.draw

polis.draw %>% filter(.draw == 1)   # unique draws per chain

polis.brm3 %>%  tidy_draws() %>% # gives wide data table
  mutate(LD50 = (-1 * b_Intercept) / b_RATIO) %>% # 1,500 LD50s at end of table
  median_hdci(LD50)
```

# Summary figure {.tabset .tabset-faded}

Run the same via emmeans with frequentist.

```{r emmeans}
polis.grid <- with(polis, list(RATIO = modelr::seq_range(RATIO, n = 100)))
newdata <- polis.brm3 %>% 
  emmeans(~ RATIO, at = polis.grid, type = 'response') %>% 
  as.data.frame()
head(newdata)

newdata %>% 
  ggplot(aes(y = prob, x = RATIO)) +
  geom_line() +
  geom_ribbon(aes(ymin = lower.HPD, ymax = upper.HPD), fill = 'turquoise', alpha = 0.3) +
  geom_point(data = polis, aes(y = PA)) +
  scale_y_continuous('PA') +
  scale_x_continuous('RATIO') +
  theme_classic()
```

Spaghetti type plot here

New predicted data has 100 x 1,500 draws. Draw the 100 points for each draw - 15,00 lines being drawn, connecting 100 points per line. `group` ensures each line drawn separately.

*Plot represents 1,500 realizations drawn from the posterior.*

Each one is possible actual population trend.

```{r spaghetti summary plot}
newdata <- polis.brm3 %>% 
  emmeans(~ RATIO, at = polis.grid, type = 'link') %>% # default goes to summary or print function
  gather_emmeans_draws() %>% # gathers all draws and puts back all columns which is needed for spaghetti plot
  mutate(Prob = plogis(.value))

line <- newdata %>% group_by(RATIO) %>% 
  summarize(Med = median(plogis(.value)))

newdata %>% 
  ggplot() +
  geom_line(aes(y = Prob, x = RATIO, group = .draw, color = factor(.draw)),
            alpha = 0.05, show.legend = FALSE) +
  geom_point(data = polis, aes(y = PA, x = RATIO)) +
  geom_line(data = line, aes(y = Med, x = RATIO), color = 'black') +
  theme_classic()
  
```


# References
