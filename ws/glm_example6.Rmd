---
title: "GLM Part6"
author: "Murray Logan"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  html_document:
    code_folding: show
    collapse: no
    df_print: paged
    fig_caption: yes
    fig_height: 4
    fig_width: 4
    highlight: textmate
    theme: spacelab
    toc: yes
    toc_float: yes
    css: ../resources/style.css
  pdf_document:
    df_print: default
    fig_caption: yes
    fig_height: 4
    fig_width: 4
    highlight: tango
    latex_engine: xelatex
    number_sections: yes
    toc_depth: 2
  word_document:
    fig_caption: yes
    fig_height: 4
    fig_width: 4
    highlight: tango
    toc: yes
    toc_depth: 2
output_dir: "docs"
documentclass: article
fontsize: 12pt
mainfont: Arial
mathfont: LiberationMono
monofont: DejaVu Sans Mono
classoption: a4paper
bibliography: ../resources/references.bib
---

```{r setup, include=FALSE, warnings=FALSE, message=FALSE}
knitr::opts_chunk$set(echo = TRUE, message=FALSE, warning=FALSE,cache.lazy = FALSE, tidy='styler')
```

# Preparations

Load the necessary libraries

```{r libraries, results='markdown', eval=TRUE, message=FALSE, warning=FALSE}
library(car)       #for regression diagnostics
library(broom)     #for tidy output
library(ggfortify) #for model diagnostics
library(sjPlot)    #for outputs
library(knitr)     #for kable
library(effects)   #for partial effects plots
library(emmeans)   #for estimating marginal means
library(ggeffects) #for plotting marginal means
library(MASS)      #for glm.nb
library(MuMIn)     #for AICc
library(tidyverse) #for data wrangling
library(modelr)    #for auxillary modelling functions
library(DHARMa)    #for residual diagnostics plots
library(performance) #for residuals diagnostics
library(see)         #for plotting residuals
library(patchwork) #grid of plots
library(scales)    #for more scales
```

# Scenario

An ecologist studying a rocky shore at Phillip Island, in southeastern
Australia, was interested in how clumps of intertidal mussels are maintained [@Quinn-1988-137]. In particular, he wanted to know how densities of adult mussels affected recruitment of young individuals from the plankton. As with most marine invertebrates, recruitment is highly patchy in time, so he expected to find seasonal variation, and the interaction between season and density - whether effects of adult mussel density vary across seasons - was the aspect of most interest.

The data were collected from four seasons, and with two densities of adult mussels. The experiment consisted of clumps of adult mussels attached to the rocks. These clumps were then brought back to the laboratory, and the number of baby mussels recorded. There were 3-6 replicate clumps for each density and season combination.

Format of quinn.csv data files

SEASON   DENSITY   RECRUITS   SQRTRECRUITS   GROUP
-------- --------- ---------- -------------- ------------
Spring   Low       15         3.87           SpringLow
..       ..        ..         ..             ..
Spring   High      11         3.32           SpringHigh
..       ..        ..         ..             ..
Summer   Low       21         4.58           SummerLow
..       ..        ..         ..             ..
Summer   High      34         5.83           SummerHigh
..       ..        ..         ..             ..
Autumn   Low       14         3.74           AutumnLow
..       ..        ..         ..             ..

------------------ --------------------------------------------------------------------------------------------
**SEASON**         Categorical listing of Season in which mussel clumps were collected ­ independent variable
**DENSITY**        Categorical listing of the density of mussels within mussel clump ­ independent variable
**RECRUITS**       The number of mussel recruits ­ response variable
**SQRTRECRUITS**   Square root transformation of RECRUITS - needed to meet the test assumptions
**GROUPS**         Categorical listing of Season/Density combinations - used for checking ANOVA assumptions
------------------ --------------------------------------------------------------------------------------------

![Mussel](../resources/mussels.jpg){height="300"}

# Read in the data

```{r readData, results='markdown', eval=TRUE}
quinn = read_csv('../data/quinn.csv', trim_ws=TRUE)
glimpse(quinn)
summary(quinn)
```

Since we intend to model both SEASON and DENSITY as categorical variables, we need to explicitly declare them as factors.

Plot to see factor order of seasons: 

```{r boxplot}
ggplot(quinn, aes(y = RECRUITS, x = SEASON, fill = DENSITY)) +
  geom_boxplot()
```

```{r change order of seasons}
quinn <- quinn %>% 
  mutate(SEASON = factor(SEASON, levels = c('Spring', 'Summer', 'Autumn', 'Winter')),
         DENSITY = factor(DENSITY))
```

# Exploratory data analysis

Trend with mean and variance?

Size of boxplot ~ variance
Some higher means (bar is median) have higher variance. Is expected with Poisson distribution. Some exceptions - Autumn-Low. Could be overdispersed.

If log response the higher mean, higher variance relationship should result in equal sized boxes as response increases.

Winter-Low looks like it is 0-inflated.

```{r redo boxplot}
ggplot(quinn, aes(y = RECRUITS, x = SEASON, fill = DENSITY)) +
  geom_boxplot()

ggplot(quinn, aes(y = RECRUITS, x = SEASON, fill = DENSITY)) +
  geom_boxplot() +
  scale_y_log10()
```

Model formula:
$$
\begin{align}
y_i &\sim{} \mathcal{Pois}(\lambda_i)\\
ln(\mu_i) &= \boldsymbol{\beta} \bf{X_i}\\[1em]
\end{align}
$$
                                           
where $\boldsymbol{\beta}$ is a vector of effects parameters and $\bf{X}$ is a
model matrix representing the intercept and effects of season, density and their
interaction on mussel recruitment.


**Conclusions:**

- there is clear evidence of non-homogeneity of variance
- specifically, there is evidence that the variance is related to the mean in
  that boxplots that are lower on the y-axis (low mean) also have lower variance
  (shorter boxplots)
- this might be expected for count data and we might consider that a Poisson
  distribution (which assumes that mean and variance are equal - and thus
  related in a very specific way).

Lets mimic the effect of using a log link, by using log scaled y-axis.


**Conclusions:**

- that is an improvement

> When design is not balanced, default ANOVA tables could be wrong. Don't look at an ANOVA table. Rare to have truly balanced design and can be misleading. ANOVA table does not tell us as much as the summary.

# Fit the model {.tabset .tabset-faded}

```{r poisson glm}
quinn.glm <- glm(RECRUITS ~ DENSITY * SEASON, data = quinn,
                 family = poisson(link = 'log'))
```

# Model validation {.tabset .tabset-faded}

## autoplot

First 2 okay. Don't need to worry about scale-location much.

Cook's Distance has influential point.

```{r autoplot}
quinn.glm %>% autoplot(which = 1:4)
```

## performance

Homogeneity ideally centered - first group line closest to y-axis is all above the line.
Multicollinearity not relevant to categorical factors.

```{r check_model}
quinn.glm %>% performance::check_model()
```

Doubt cast that the model is good.

Want an overdispersion value of 1 $\mu = \sigma^2$

Dispersion ratio is 3.309 and greater than 3.

Causes of overdispersion:

1. Zero inflated
    - Poisson not expecting that many 0s. too many 0s will not estimate correctly.
    - Two things: the data generation process and ability to detect.
2. Model too simple
    - Modeling recruitment in seasons and density. Other factors not captured (orientation of rock, relationship to tide line) could be important and could incorporate into the model (if you have the data).
    - Add a dummy variable as a proxy for all the things you have not collected. An **observation level random effect**. Add a column of 1s. Soaks up the extra variance.
    - Warning: It can have a statisticak *shrinkage* effect. Shrinks estimates toward the center. If have 2 groups (high/low density) can shrink so 2 groups are less different. Especially if have small dataset.
3. 

```{r check overdispersion}
quinn.glm %>% performance::check_overdispersion()
```

Here is saying have 2 0s and expect 0. Saying zero inflated but is okay. Guide of 20% of data is good. Here, 2 out of ~40 is ok. Both 0s are in the same group which is not ideal.

```{r check zero inflation}
quinn.glm %>% performance::check_zeroinflation()

```

## DHARMa residuals

will only flag there is a problem versus give values above as it is comparine actual versus simulated residuals.

Failing on overdispersion and outliers. Outliers on bottom level so most likely 0s.

```{r dharma}
quinn.resid <- quinn.glm %>% simulateResiduals(plot = TRUE)
```

```{r dharma dispersion test}
quinn.resid %>% testDispersion()
```

Have 2, simulate  mostly expect 0 zeros.

```{r 0 inflation}
quinn.resid %>% testZeroInflation()
```

Aggregating or clumping of data. Normally expect things to be homogeneous in their distribution. If so, negative binomial would be better - sometimes 0 sometimes not is expected in this distribution. Poisson expects more uniform distribution.

Binomial good for clumpiness, but not for drastic (>20%) zer inflation. Looks very Poisson-y.

# Different model {.tabset .tabset-faded}

For simple model like this, cannot adjust GLM. 

`MASS::glm.nb` only runs negative binomial.

```{r}
quinn.nb <- MASS::glm.nb(RECRUITS ~ DENSITY * SEASON, data = quinn)
```

## Diagnostics

Outlier still not fantastic.

```{r nb autoplot}
quinn.nb %>% autoplot(which = 1:6)
```

```{r nb checkmodel}
quinn.nb %>% performance::check_model()
```

Overdisperson with DHARMa looks better. Not all tests create equal.

**Why is overdisperson a problem? **

It underestimates the standard errors in slopes, etc. Gives you Type I errors, makes your estimates seem more precise than they should be.

Early way of addressing overdispersion was to adjust df to compensate with 'quasi' models. Overdisperson increases power, decrease df to compensate and hopefully end up back where should be. Problem - adjusting df is approximate. No way of knowing how well it is doing. Band-aid solution. Can't use AIC with quasi models. *No need to use quasi models anymore*. New tools like negative binomial.

```{r nb dharma}
quinn.resid <- quinn.nb %>% 
  simulateResiduals(plot = TRUE)
```

# Partial plots {.tabset .tabset-faded}

Effect of DENSITY in the summer but not in the other seasons.

```{r nb plot_model}
quinn.nb %>% plot_model(type = 'eff', terms = c('SEASON', 'DENSITY')) # put both variables on the one graph to see interaction
```

This plot is just giving first level of Density: a **conditional** plot. Same as red lines in previous plot. Not averaged over DENSITY.

`ggpredict()` is always conditional - need to define parameters.

```{r conditional season plot}
quinn.nb %>% ggpredict(c('SEASON')) %>% plot()
```

Marginalized plot over DENSITY.

emmeans awalsy marginal.

```{r marginal}
quinn.nb %>% ggemmeans(c('SEASON')) %>% plot()
```

Interaction is the same. 

```{r plot interaction}
quinn.nb %>% ggemmeans(~ SEASON * DENSITY) %>% plot()
```

# Model investigation / hypothesis testing {.tabset .tabset-faded}

ANOVA told us effect of SEASON and an interaction. 

> ANOVA bit obsolete. Stems from having to push a button.

Here we can get same information plus a lot more.

Look at interactions first.
    - DENSITY effect is different in Summer than in Spring-High (first level).
    - Do not just describe main effects. 
    
> If no significant interactions - can you run the model with just additive fixed effects?
- Frequentist: Can to save df. Trade off between reduce unexplained variability versus saving df.
- Bayesian: Leave in because there is no df and will reduce unexplained variability.

## Model summary - link scale

```{r model summary}
quinn.nb %>% summary()
```

## Tidy summary 

Intercept 10 - rounded number of recruits in Spring-High.
DENSITYLow - 1.12 fold difference to intercept. 12% increase.
SEASONSummer - for High Density, 4.82 fold increase, 382% change.

```{r back transformed summary}
quinn.nb %>% tidy(conf.int = TRUE, exponentiate = TRUE) # back transform
```

For interactions, split variables apart. Captured within the same analysis is okay.

- Is there a seasonal effect for High? Low?
- Is there a density effect in Spring? Summer? 

Could filter data just for Spring and do a t-test for all seasons, but you don't. Tests are based on unexplained variability. So if you filter out data have greater variability and lower df. Still want to do it within the one analysis to keep the df. Within the context of the full model to have the power of the full model.

# Further analysis

emmeans estimate marginal means for DESNTIY separate for each season. Follow through to pairswise comparisons.

On log scale. Back to factor scale put 'type = 'response'' - fold factor representation.

Summer High/Low - High is 2.19 fold, 119% higher, evidence of effect from  significant p-value
Autumn High/Low - 1.08 fold, 8% higher
Winter High/Low - 2.12 fold, 112$ higher

```{r }
eff <- quinn.nb %>% emmeans(~ DENSITY|SEASON, type = 'response') %>% 
  pairs() %>% 
  summary(infer = TRUE) %>% 
  as.data.frame()
eff
```

Ratio scale not really fair to left side of 1 - very much skewed to positive effects downplaying the negative effects.

consider scaling x axis so it is more symmetrical.

Also, pseudo log scale if want to log-scale axis including 0.

> For log transforming predictors use lowest value divided by half. Don't want super small number otherwise will be an outlier.

```{r catepillar plot season}
ggplot(eff, aes(x = ratio, y = SEASON)) + 
  geom_vline(xintercept = 1, linetype = 'dashed') +
  geom_linerange(aes(xmin = asymp.LCL, xmax = asymp.UCL)) +
  geom_point() +
  scale_y_discrete(name = '')  + # no lable needed bc seasons are descriptive
  scale_x_continuous(name = 'Density effect (High vs Low)',
                     trans = scales::log2_trans(),
                     breaks = scales::breaks_log(base = 2)) +
  geom_text(aes(label = sprintf("p=%.2f", p.value)), # sprintf from C, like a paste/quote, %.2 - format w 2 decimals, f - float, formatting the p.value from model
            nudge_y = 0.25) + # nudge off the point
  theme_classic() -> p.seas

p.seas

log2(2)
log2(.5)
```

What is the difference between Summer High/Low on an absolute scale?

Can do both and discuss:

The difference between Summer High/Low was 26 which represents an X fold/X percent change.

Table or figure. Catepillar plots, etc. 

```{r}
season.eff <- quinn.nb %>% emmeans(~ DENSITY|SEASON, type = 'link') %>% 
  regrid() %>% # back transform before pairs() comparison
  pairs() %>% 
  summary(infer = TRUE) %>% 
  as.data.frame()
season.eff
```

# Predictions

```{r}
newdata <-emmeans(quinn.nb, ~ DENSITY | SEASON, type = 'response') %>% 
  as.data.frame()
head(newdata)
```

## Interaction plot

'shape = DENSITY' outside of `aes()` need to specify shape number and will not change with levels of DENSITY.

Two ways of distinguishing things - don't have to worry about color-blind friendly etc. 

```{r season density interaction plot}
ggplot(newdata, aes(x = SEASON, y = response, fill = DENSITY)) + # fill will only do point shape with area to fill
  geom_pointrange(aes(ymin = asymp.LCL, ymax = asymp.UCL, 
                      shape = DENSITY), # shape in aes() has a scale
                  position = position_dodge(width = 0.2)) +
  scale_shape_manual(values = c(21, 22)) + # change scale of shape to fillable shape
  theme_classic() -> ip
```

Add annotations:

Automatically puts * in the middle of Summer. 

Not recommned to star significance by Murray. Catepillar plot is better
```{r annotation}
ip +
  annotate(geom = 'text', x = 'Summer', y = 70, label = '*', size = 7) -> ip
ip
```


# Summary figures

As these summarise only involve categorical predictors, there is no need to define a prediction grid.  For categorical predictors, the default grid will assume that you are interested in all the levels of the categorical predictors.

```{r}
(ip + ggtitle('a)')) + (p.seas + ggtitle('b)'))
```

Traditionally, plot on left would be bar graph with shaded bar - dynamite plot'. Dangerous because only top of bar has meaning.

# Investigatin zero inflated models w simple example

glmmTMB
mm - mixed effects
TMB - template model builder, depending on package

Very flexible package, does everything.

```{r read in glmmTMB}
library(glmmTMB)
```

# Fit glmmTMB model

Data generation process - Poisson. Determines how many recruits.

On top of that - whether you can detect them. There were 1, 2, 3 but didn't detect them **false zeros**.

Model will separate out into 2 processes:

1. Determine rate of false zeros - likely to be true/false. Binomial-Bernoulli process of counting zeros. Can only been in one of two states
2. Count process is Poisson.

A mixture of two models (not a mixed model).

```{r fit zi model}
quinn.zip <- glmmTMB(RECRUITS ~ DENSITY * SEASON,
                     zi = ~1, # fiting zero inflated model
                     data = quinn,
                     family = poisson())
```

Lots of validation functions don't work well with zi modesl - DHARMa does.

Before with Poisson was overdispersed. Here is not. Zero inflated model can be overdispered, can run a zero inflated negative binomial model.

```{r ZI DHARMa}
quinn.resid <- quinn.zip %>% simulateResiduals(plot = TRUE)
```

Output in 2 parts:

1. Conditional model - same as above
2. Zero inflated part - modelled as ~ 1 (intercept only)
    - Intercept = -3 - log-odds ratio
        - odds-ratio: probability of zeros being true to false
        - plogis: proportion of zeros that are false
  
```{r ZIP summary}
quinn.zip %>% summary()

exp(-3.007)
plogis(-3.007) # 5% of zeros are false zeros
```

Saw zeros were all in one group.

Conditional model is main result - the ecology.

Zero-inflation model - speaks to methodology.

- Detectability is significantly higher in Summer than Winter, when density is high...

Only difference - CIs would be different. 

```{r adding zip interaction}
quinn.zip <- glmmTMB(RECRUITS ~ DENSITY * SEASON,
                      zi = ~ DENSITY * SEASON,
                      data = quinn, 
                      family = poisson())
quinn.zip %>% summary
```


# References
