---
title: "GLM Part6"
author: "Murray Logan"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  html_document:
    code_folding: show
    collapse: no
    df_print: paged
    fig_caption: yes
    fig_height: 4
    fig_width: 4
    highlight: textmate
    theme: spacelab
    toc: yes
    toc_float: yes
    css: ../resources/style.css
  pdf_document:
    df_print: default
    fig_caption: yes
    fig_height: 4
    fig_width: 4
    highlight: tango
    latex_engine: xelatex
    number_sections: yes
    toc_depth: 2
  word_document:
    fig_caption: yes
    fig_height: 4
    fig_width: 4
    highlight: tango
    toc: yes
    toc_depth: 2
output_dir: "docs"
documentclass: article
fontsize: 12pt
mainfont: Arial
mathfont: LiberationMono
monofont: DejaVu Sans Mono
classoption: a4paper
bibliography: ../resources/references.bib
---

```{r setup, include=FALSE, warnings=FALSE, message=FALSE}
knitr::opts_chunk$set(echo = TRUE, message=FALSE, warning=FALSE,cache.lazy = FALSE, tidy='styler')
```

# Preparations

Load the necessary libraries

```{r libraries, results='markdown', eval=TRUE, message=FALSE, warning=FALSE}
library(car)       #for regression diagnostics
library(broom)     #for tidy output
library(ggfortify) #for model diagnostics
library(sjPlot)    #for outputs
library(knitr)     #for kable
library(effects)   #for partial effects plots
library(emmeans)   #for estimating marginal means
library(ggeffects) #for plotting marginal means
library(MASS)      #for glm.nb
library(MuMIn)     #for AICc
library(tidyverse) #for data wrangling
library(modelr)    #for auxillary modelling functions
library(DHARMa)    #for residual diagnostics plots
library(performance) #for residuals diagnostics
library(see)         #for plotting residuals
library(patchwork) #grid of plots
library(scales)    #for more scales
```

# Scenario

An ecologist studying a rocky shore at Phillip Island, in southeastern
Australia, was interested in how clumps of intertidal mussels are maintained [@Quinn-1988-137]. In particular, he wanted to know how densities of adult mussels affected recruitment of young individuals from the plankton. As with most marine invertebrates, recruitment is highly patchy in time, so he expected to find seasonal variation, and the interaction between season and density - whether effects of adult mussel density vary across seasons - was the aspect of most interest.

The data were collected from four seasons, and with two densities of adult mussels. The experiment consisted of clumps of adult mussels attached to the rocks. These clumps were then brought back to the laboratory, and the number of baby mussels recorded. There were 3-6 replicate clumps for each density and season combination.

Format of quinn.csv data files

SEASON   DENSITY   RECRUITS   SQRTRECRUITS   GROUP
-------- --------- ---------- -------------- ------------
Spring   Low       15         3.87           SpringLow
..       ..        ..         ..             ..
Spring   High      11         3.32           SpringHigh
..       ..        ..         ..             ..
Summer   Low       21         4.58           SummerLow
..       ..        ..         ..             ..
Summer   High      34         5.83           SummerHigh
..       ..        ..         ..             ..
Autumn   Low       14         3.74           AutumnLow
..       ..        ..         ..             ..

------------------ --------------------------------------------------------------------------------------------
**SEASON**         Categorical listing of Season in which mussel clumps were collected ­ independent variable
**DENSITY**        Categorical listing of the density of mussels within mussel clump ­ independent variable
**RECRUITS**       The number of mussel recruits ­ response variable
**SQRTRECRUITS**   Square root transformation of RECRUITS - needed to meet the test assumptions
**GROUPS**         Categorical listing of Season/Density combinations - used for checking ANOVA assumptions
------------------ --------------------------------------------------------------------------------------------

![Mussel](../resources/mussels.jpg){height="300"}

# Read in the data

```{r readData, results='markdown', eval=TRUE}
quinn = read_csv('../data/quinn.csv', trim_ws=TRUE)
glimpse(quinn)
summary(quinn)
```

Since we intend to model both SEASON and DENSITY as categorical variables, we need to explicitly declare them as factors.

Plot to see factor order of seasons: 

```{r boxplot}
ggplot(quinn, aes(y = RECRUITS, x = SEASON, fill = DENSITY)) +
  geom_boxplot()
```

```{r change order of seasons}
quinn <- quinn %>% 
  mutate(SEASON = factor(SEASON, levels = c('Spring', 'Summer', 'Autumn', 'Winter')),
         DENSITY = factor(DENSITY))
```

# Exploratory data analysis

Trend with mean and variance?

Size of boxplot ~ variance
Some higher means (bar is median) have higher variance. Is expected with Poisson distribution. Some exceptions - Autumn-Low. Could be overdispersed.

If log response the higher mean, higher variance relationship should result in equal sized boxes as response increases.

Winter-Low looks like it is 0-inflated.

```{r redo boxplot}
ggplot(quinn, aes(y = RECRUITS, x = SEASON, fill = DENSITY)) +
  geom_boxplot()

ggplot(quinn, aes(y = RECRUITS, x = SEASON, fill = DENSITY)) +
  geom_boxplot() +
  scale_y_log10()
```

Model formula:
$$
\begin{align}
y_i &\sim{} \mathcal{Pois}(\lambda_i)\\
ln(\mu_i) &= \boldsymbol{\beta} \bf{X_i}\\[1em]
\end{align}
$$
                                           
where $\boldsymbol{\beta}$ is a vector of effects parameters and $\bf{X}$ is a
model matrix representing the intercept and effects of season, density and their
interaction on mussel recruitment.


**Conclusions:**

- there is clear evidence of non-homogeneity of variance
- specifically, there is evidence that the variance is related to the mean in
  that boxplots that are lower on the y-axis (low mean) also have lower variance
  (shorter boxplots)
- this might be expected for count data and we might consider that a Poisson
  distribution (which assumes that mean and variance are equal - and thus
  related in a very specific way).

Lets mimic the effect of using a log link, by using log scaled y-axis.


**Conclusions:**

- that is an improvement

> When design is not balanced, default ANOVA tables could be wrong. Don't look at an ANOVA table. Rare to have truly balanced design and can be misleading. ANOVA table does not tell us as much as the summary.

# Fit the model {.tabset .tabset-faded}

```{r poisson glm}
quinn.glm <- glm(RECRUITS ~ DENSITY * SEASON, data = quinn,
                 family = poisson(link = 'log'))
```

# Model validation {.tabset .tabset-faded}

## autoplot

First 2 okay. Don't need to worry about scale-location much.

Cook's Distance has influential point.

```{r autoplot}
quinn.glm %>% autoplot(which = 1:4)
```

## performance

Homogeneity ideally centered - first group line closest to y-axis is all above the line.
Multicollinearity not relevant to categorical factors.

```{r check_model}
quinn.glm %>% performance::check_model()
```

Doubt cast that the model is good.

Want an overdispersion value of 1 $\mu = \sigma^2$

Dispersion ratio is 3.309 and greater than 3.

Causes of overdispersion:

1. Zero inflated
    - Poisson not expecting that many 0s. too many 0s will not estimate correctly.
    - Two things: the data generation process and ability to detect.
2. Model too simple
    - Modeling recruitment in seasons and density. Other factors not captured (orientation of rock, relationship to tide line) could be important and could incorporate into the model (if you have the data).
    - Add a dummy variable as a proxy for all the things you have not collected. An **observation level random effect**. Add a column of 1s. Soaks up the extra variance.
    - Warning: It can have a statisticak *shrinkage* effect. Shrinks estimates toward the center. If have 2 groups (high/low density) can shrink so 2 groups are less different. Especially if have small dataset.
3. 

```{r check overdispersion}
quinn.glm %>% performance::check_overdispersion()
```

Here is saying have 2 0s and expect 0. Saying zero inflated but is okay. Guide of 20% of data is good. Here, 2 out of ~40 is ok. Both 0s are in the same group which is not ideal.

```{r check zero inflation}
quinn.glm %>% performance::check_zeroinflation()

```

## DHARMa residuals

will only flag there is a problem versus give values above as it is comparine actual versus simulated residuals.

Failing on overdispersion and outliers. Outliers on bottom level so most likely 0s.

```{r dharma}
quinn.resid <- quinn.glm %>% simulateResiduals(plot = TRUE)
```

```{r dharma dispersion test}
quinn.resid %>% testDispersion()
```

Have 2, simulate  mostly expect 0 zeros.

```{r 0 inflation}
quinn.resid %>% testZeroInflation()
```

Aggregating or clumping of data. Normally expect things to be homogeneous in their distribution. If so, negative binomial would be better - sometimes 0 sometimes not is expected in this distribution. Poisson expects more uniform distribution.

Binomial good for clumpiness, but not for drastic (>20%) zer inflation. Looks very Poisson-y.

# Different model {.tabset .tabset-faded}

For simple model like this, cannot adjust GLM. 

`MASS::glm.nb` only runs negative binomial.

```{r}
quinn.nb <- MASS::glm.nb(RECRUITS ~ DENSITY * SEASON, data = quinn)
```

## Diagnostics

Outlier still not fantastic.

```{r nb autoplot}
quinn.nb %>% autoplot(which = 1:6)
```

```{r nb checkmodel}
quinn.nb %>% performance::check_model()
```

Overdisperson with DHARMa looks better. Not all tests create equal.

**Why is overdisperson a problem? **

It underestimates the standard errors in slopes, etc. Gives you Type I errors, makes your estimates seem more precise than they should be.

Early way of addressing overdispersion was to adjust df to compensate with 'quasi' models. Overdisperson increases power, decrease df to compensate and hopefully end up back where should be. Problem - adjusting df is approximate. No way of knowing how well it is doing. Band-aid solution. Can't use AIC with quasi models. *No need to use quasi models anymore*. New tools like negative binomial.

```{r nb dharma}
quinn.resid <- quinn.nb %>% 
  simulateResiduals(plot = TRUE)
```

# Partial plots {.tabset .tabset-faded}

Effect of DENSITY in the summer but not in the other seasons.

```{r nb plot_model}
quinn.nb %>% plot_model(type = 'eff', terms = c('SEASON', 'DENSITY')) # put both variables on the one graph to see interaction
```


# Model investigation / hypothesis testing {.tabset .tabset-faded}


# Predictions


# Summary figures
As these summarise only involve categorical predictors, there is no need to
define a prediction grid.  For categorical predictors, the default grid will
assume that you are interested in all the levels of the categorical predictors.



# References
